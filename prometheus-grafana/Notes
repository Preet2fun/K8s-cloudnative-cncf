# How to Setup Prometheus Monitoring On Kubernetes Cluster

we will create a Kubernetes namespace for all our monitoring components

kubectl create namespace monitoring

Step 1: Create a file named clusterRole.yaml.
Step 2: Create the role using the following command.
kubectl create -f clusterRole.yaml

Create a Config Map To Externalize Prometheus Configurations
All configurations for Prometheus are part of prometheus.yaml file and all the alert rules for Alertmanager are configured in prometheus.rules.

prometheus.yaml: This is the main Prometheus configuration which holds all the scrape configs, service discovery details, storage locations, data retention configs, etc)

prometheus.rules: This file contains all the Prometheus alerting rules

By externalizing Prometheus configs to a Kubernetes config map, you don’t have to build the Prometheus image whenever you need to add or remove a configuration. You need to update the config map and restart the Prometheus pods to apply the new configuration.

Step 1: Create a file called config-map.yaml.
Step 2: Execute the following command to create the config map in Kubernetes.

kubectl create -f config-map.yaml

The prometheus.yaml contains all the configurations to discover pods and services running in the Kubernetes cluster dynamically. We have the following scrape jobs in our Prometheus scrape configuration.

1) kubernetes-apiservers: It gets all the metrics from the API servers.
2) kubernetes-nodes: It collects all the kubernetes node metrics.
3) kubernetes-pods: All the pod metrics get discovered if the pod metadata is annotated with prometheus.io/scrape and prometheus.io/port annotations.
4) kubernetes-cadvisor: Collects all cAdvisor metrics.
5) kubernetes-service-endpoints: All the Service endpoints are scrapped if the service metadata is annotated with prometheus.io/scrape and prometheus.io/port annotations. It can be used for black-box monitoring.

Step 1: Create a file named prometheus-deployment.yaml. In this configuration, we are mounting the Prometheus config map as a file inside /etc/prometheus

Step 2: Create a deployment on monitoring namespace using the above file.
kubectl create  -f prometheus-deployment.yaml 

Step 3: You can check the created deployment using the following command.
kubectl get deployments --namespace=monitoring

Exposing Prometheus as a Service [NodePort & LoadBalancer]
To access the Prometheus dashboard over a IP or a DNS name, you need to expose it as a Kubernetes service.

Step 1: Create a file named prometheus-service.yaml. We will expose Prometheus on all kubernetes node IP’s on port 30000.

Step 2: Create the service using the following command.
kubectl create -f prometheus-service.yaml --namespace=monitoring

Step 3: Once created, you can access the Prometheus dashboard using any of the Kubernetes node’s IP on port 30000. If you are on the cloud, make sure you have the right firewall rules to access port 30000 from your workstation.



# Kube State Metrics


Primarily it produces metrics in Prometheus format with the stability as the Kubernetes API. Overall it provides kubernetes objects & resources metrics that you cannot get directly from native Kubernetes monitoring components.

Kube state metrics service exposes all the metrics on /metrics URI. Prometheus can scrape all the metrics exposed by Kube state metrics.

Following are some of the important metrics you can get from Kube state metrics.

Node status, node capacity (CPU and memory)
Replica-set compliance (desired/available/unavailable/updated status of replicas per deployment)
Pod status (waiting, running, ready, etc)
Ingress metrics
PV, PVC metrics
Daemonset & Statefulset metrics.
Resource requests and limits.
Job & Cronjob metrics

Kube state metrics is available as a public docker image. You will have to deploy the following Kubernetes objects for Kube state metrics to work.

1) Service Account
2) Cluster Role – For kube state metrics to access all the Kubernetes API objects.
3) Cluster Role Binding – Binds the service account with the cluster role.
4) Kube State Metrics Deployment
5) Service – To expose the metrics

All the above Kube state metrics objects will be deployed in the kube-system namespace

Step 1: Clone the Github repo

git clone https://github.com/devopscube/kube-state-metrics-configs.git
Step 2: Create all the objects by pointing to the cloned directory.

kubectl apply -f kube-state-metrics-configs/
Step 3: Check the deployment status using the following command.

kubectl get deployments kube-state-metrics -n kube-system

All the Kube static metrics can be obtained from the Kube state service endpoint on /metrics URI.

This configuration can be added as part of the Prometheus job configuration. You need to add the following job configuration to your Prometheus config for Prometheus to scrape all the Kube state metrics.

- job_name: 'kube-state-metrics'
  static_configs:
    - targets: ['kube-state-metrics.kube-system.svc.cluster.local:8080']

# Grafana

Deploy Grafana On Kubernetes
Let’s look at the Grafana setup in detail.

Step 1: Create a file named grafana-datasource-config.yaml
vi grafana-datasource-config.yaml

Step 2: Create the configmap using the following command.
kubectl create -f grafana-datasource-config.yaml

Step 3: Create a file named deployment.yaml
vi deployment.yaml

Note: This Grafana deployment does not use a persistent volume. If you restart the pod all changes will be gone. Use a persistent volume if you are deploying Grafana for your project requirements. It will persist all the configs and data that Grafana uses.

Step 4: Create the deployment
kubectl create -f deployment.yaml

Step 5: Create a service file named service.yaml
vi service.yaml

Step 6: Create the service.

kubectl create -f service.yaml
Now you should be able to access the Grafana dashboard using any node IP on port 32000. Make sure the port is allowed in the firewall to be accessed from your workstation.

http://<your-node-ip>:32000

